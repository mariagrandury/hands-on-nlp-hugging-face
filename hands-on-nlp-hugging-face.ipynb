{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Hands-on NLP with Hugging Face",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjBSKwYPzVg8V1DOn9TYXs",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0009ab90e16d4edbb12eab8f01a557dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cbf4046c1654a659437c4a2cdeaf921",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e51b4b9f2017415fb7d267bf52fb0066",
              "IPY_MODEL_bc2a670427884dc3a7f66bb1a0411e3c"
            ]
          }
        },
        "3cbf4046c1654a659437c4a2cdeaf921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e51b4b9f2017415fb7d267bf52fb0066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40e1467eeeaa40f49d6647557da67ed7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2347,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2347,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2111ae0fde245aa96e1f27f7e1d57c1"
          }
        },
        "bc2a670427884dc3a7f66bb1a0411e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f3c1b6d47034d14a92e37b44ba33dba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2347/2347 [06:12&lt;00:00,  6.30ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_aba03309ee0842eba6273595209fb422"
          }
        },
        "40e1467eeeaa40f49d6647557da67ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2111ae0fde245aa96e1f27f7e1d57c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f3c1b6d47034d14a92e37b44ba33dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "aba03309ee0842eba6273595209fb422": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariagrandury/hands-on-nlp-hugging-face/blob/main/hands-on-nlp-hugging-face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8uL_goZgzhK"
      },
      "source": [
        "<h1 align=\"center\">\n",
        "Hands-on NLP with Hugging Face \n",
        "</h1>\n",
        "\n",
        "<p align=\"center\">\n",
        "NLP Workshop at the <a href=\"https://www.womentech.net/women-tech-conference\"> WomenTech Global Conference 2021</a>.\n",
        "</p>\n",
        "\n",
        "<p align=\"center\">\n",
        "<br>\n",
        "<img src=\"https://pbs.twimg.com/media/E24NHqOWEA0AxRE?format=jpg&name=medium\" alt=\"logo\" width=\"400\"/>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERooc1BEkCIl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2oNbiNTefC3"
      },
      "source": [
        "# We won't need TensorFlow here\n",
        "!pip uninstall -y tensorflow\n",
        "\n",
        "# Install `datasets`\n",
        "!pip install datasets\n",
        "\n",
        "# Install `transformers` from master\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip list | grep -E 'transformers|tokenizers'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0KybKWbgf3E"
      },
      "source": [
        "# ðŸ¤— Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i5UhFyV0564"
      },
      "source": [
        "We are going to use the data set [Spanish Billion Words](https://huggingface.co/datasets/spanish_billion_words) (10.22 GiB)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9sgLpWReDfI",
        "outputId": "082656a3-7ed2-4d8e-be03-350cd019adc1"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"spanish_billion_words\", split='train[:5%]')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset spanish_billion_words (/root/.cache/huggingface/datasets/spanish_billion_words/corpus/1.1.0/8ba50a854d61199f7d36b4c3f598589a2f8b493a2644b88ce80adb2cebcbc107)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VYNM82-ngoy",
        "outputId": "9cd144fa-d010-4c05-d40e-d3240190123a"
      },
      "source": [
        "print(len(dataset))\n",
        "print(dataset[23])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2346265\n",
            "{'text': 'El seÃ±or John Dashwood no tenÃ­a la profundidad de sentimientos del resto de la familia pero sÃ­ le afectÃ³ una recomendaciÃ³n de tal Ã­ndole en un momento como Ã©se y prometiÃ³ hacer todo lo que le fuera posible por el bienestar de sus parientes'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQVoK98ChRh8"
      },
      "source": [
        "# ðŸ¤— Tokenizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbJ0jq0onana"
      },
      "source": [
        "Tokenizing a text is splitting it into words or subwords, which then are converted to ids through a look-up table. The three main types of tokenizers used in ðŸ¤— Transformers:\n",
        "- Byte-Pair Encoding (BPE)\n",
        "- WordPiece\n",
        "- SentencePiece\n",
        "\n",
        "Since we are going to train a RoBERTa-like model, we will use a Byte-level BPE tokenizer.\n",
        "\n",
        "[More info](https://huggingface.co/transformers/tokenizer_summary.html#byte-pair-encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PHWvbztqRXw"
      },
      "source": [
        "def batch_iterator(batch_size=1000):\n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        yield dataset[i : i + batch_size][\"text\"]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLYp0ULWqWRd",
        "outputId": "69044885-885f-4a72-acd0-4af717f46d71"
      },
      "source": [
        "%%time \n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "\n",
        "# Initialize a tokenizer\n",
        "tokenizer = ByteLevelBPETokenizer()\n",
        "\n",
        "# Customize training\n",
        "tokenizer.train_from_iterator(\n",
        "    iterator=batch_iterator(), \n",
        "    vocab_size=52_000,\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\n",
        "        \"<s>\",\n",
        "        \"<pad>\",\n",
        "        \"</s>\",\n",
        "        \"<unk>\",\n",
        "        \"<mask>\",\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 49s, sys: 8.19 s, total: 6min 57s\n",
            "Wall time: 3min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPOdtcm1hlMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca120a87-63f3-40e2-c814-c50c25072ab8"
      },
      "source": [
        "# Save the files\n",
        "!mkdir EsBERTa\n",
        "tokenizer.save_model(\"EsBERTa\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EsBERTa/vocab.json', 'EsBERTa/merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLSQz26sNwnT",
        "outputId": "10135632-f890-49f0-ed34-58cc6f55a694"
      },
      "source": [
        "tokenizer.save_model(\"/content/drive/MyDrive/EsBERTa\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/EsBERTa/vocab.json',\n",
              " '/content/drive/MyDrive/EsBERTa/merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VHQHdvzzUsn"
      },
      "source": [
        "Now we have two files:\n",
        "- `vocab.json`: a list of the most frequent tokens ranked by frequency\n",
        "- `merges.txt`: a list of merges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GrAwBI6Nrjh"
      },
      "source": [
        "Let's see how we can use the trained tokenizer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnKimgG0xc7V"
      },
      "source": [
        "from tokenizers.implementations import ByteLevelBPETokenizer\n",
        "from tokenizers.processors import BertProcessing\n",
        "\n",
        "\n",
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    \"./EsBERTa/vocab.json\",\n",
        "    \"./EsBERTa/merges.txt\",\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyBsu0tgxflq"
      },
      "source": [
        "tokenizer._tokenizer.post_processor = BertProcessing(\n",
        "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
        "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
        ")\n",
        "tokenizer.enable_truncation(max_length=512)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrtXW6quxgay",
        "outputId": "501bed8a-cd71-4eaa-8dd1-c60b872fe656"
      },
      "source": [
        "tokenizer.encode(\"Hola me llamo Maria.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VThHrF73h8KT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b86739-2e88-475a-8c47-256d6273d016"
      },
      "source": [
        "tokenizer.encode(\"Buenos dias, me llamo Maria.\").tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Buenos', 'Ä dias', ',', 'Ä me', 'Ä llamo', 'Ä Maria', '.', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FR5tFJbDh8Wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88f6cd87-8d22-4eae-a9b6-971df6c600ee"
      },
      "source": [
        "tokenizer.encode(\"Encantada de estar hoy aquÃ­.\").tokens"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Enc', 'ant', 'ada', 'Ä de', 'Ä estar', 'Ä hoy', 'Ä aquÃƒÅƒ', '.', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cho1ylph8AY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d91108a-fb10-469a-ecbf-f906389bffbd"
      },
      "source": [
        "tokenizer.encode(\"Me gusta mucho la divulgaciÃ³n.\").tokens"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Me', 'Ä gusta', 'Ä mucho', 'Ä la', 'Ä divulgaciÃƒÂ³n', '.', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWIkb85jh9vG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad434f1e-8dfe-448b-dc89-8d0b8ee60601"
      },
      "source": [
        "tokenizer.encode(\"Espero que os guste el taller.\").tokens"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'Espero', 'Ä que', 'Ä os', 'Ä guste', 'Ä el', 'Ä taller', '.', '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPOyMMVAoe_4",
        "outputId": "810adbf8-af40-45c4-fd7c-4e8eec6136f2"
      },
      "source": [
        "tokenizer.encode(\"estrambolico, despampanante, genialidad\").tokens"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " 'estr',\n",
              " 'amb',\n",
              " 'ol',\n",
              " 'ico',\n",
              " ',',\n",
              " 'Ä desp',\n",
              " 'am',\n",
              " 'pan',\n",
              " 'ante',\n",
              " ',',\n",
              " 'Ä gen',\n",
              " 'ialidad',\n",
              " '</s>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBGF4DbWx7Xs"
      },
      "source": [
        "# ðŸ¤— Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDuxTmAxOn3T"
      },
      "source": [
        "We are going to train a [RoBERTa](https://huggingface.co/transformers/model_doc/roberta.html)-like model. \n",
        "\n",
        "The RoBERTa model was proposed in [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. It is based on Googleâ€™s BERT model released in 2018.\n",
        "\n",
        "It builds on BERT and modifies key hyperparameters, removing the next-sentence pretraining objective and training with much larger mini-batches and learning rates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUvuDN5_yAn9",
        "outputId": "118b3da2-21f0-4415-ede0-e6c44b25c4bd"
      },
      "source": [
        "# Check that we have a GPU\n",
        "!nvidia-smi"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun  8 22:01:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8kuPypqyDmP",
        "outputId": "590e6352-6c3e-4bca-aa8e-660439aafe95"
      },
      "source": [
        "# Check that PyTorch sees it\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgYprbDoOJul"
      },
      "source": [
        "Now let's instantiate a RoBERTa model according to the specified arguments, defining the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFBjHaqyGTc"
      },
      "source": [
        "from transformers import RobertaConfig\n",
        "\n",
        "# Configure a RoBERTa model\n",
        "config = RobertaConfig(\n",
        "    vocab_size=52_000,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGguh2eSy6mj"
      },
      "source": [
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "# Create a tokenizer\n",
        "# tokenizer = RobertaTokenizerFast.from_pretrained(\"./EsBERTa\", max_len=512)\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"/content/drive/MyDrive/EsBERTa\", max_len=512)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6enttFPRy9Dy"
      },
      "source": [
        "from transformers import RobertaForMaskedLM\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForMaskedLM(config=config)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUZnLclFzFuy",
        "outputId": "a605dbfb-6221-4419-eba8-cf27068692d7"
      },
      "source": [
        "model.num_parameters()  # 84 million parameters!"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83504416"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8zNP5Y-7VVN"
      },
      "source": [
        "Now let's initialize our [transformers.Trainer](https://huggingface.co/transformers/main_classes/trainer.html#id1). We need a dataset, a data collator and some training arguments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "0009ab90e16d4edbb12eab8f01a557dc",
            "3cbf4046c1654a659437c4a2cdeaf921",
            "e51b4b9f2017415fb7d267bf52fb0066",
            "bc2a670427884dc3a7f66bb1a0411e3c",
            "40e1467eeeaa40f49d6647557da67ed7",
            "f2111ae0fde245aa96e1f27f7e1d57c1",
            "9f3c1b6d47034d14a92e37b44ba33dba",
            "aba03309ee0842eba6273595209fb422"
          ]
        },
        "id": "2aecwf9G0ilV",
        "outputId": "bc16f8be-2cb2-48d0-95a0-906dbcf4f2f9"
      },
      "source": [
        "%%time\n",
        "from transformers import LineByLineTextDataset\n",
        "\n",
        "\n",
        "def encode(examples):\n",
        "  return tokenizer(examples['text'], truncation=True, padding='max_length')\n",
        "\n",
        "dataset = dataset.map(encode, batched=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0009ab90e16d4edbb12eab8f01a557dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=2347.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 8min 28s, sys: 17.4 s, total: 8min 45s\n",
            "Wall time: 6min 46s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCCGz7cO2pJ1"
      },
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v3Sd4wx2qo5"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./EsBERTa\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_gpu_train_batch_size=64,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        ")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB6ikw2kPiEn"
      },
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=dataset,\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdJ9X4lJPm4H"
      },
      "source": [
        "Finally, let's train the model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l3d-h0j2tmP"
      },
      "source": [
        "%%time\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e6l_05X20E9"
      },
      "source": [
        "trainer.save_model(\"./EsBERTa\")\n",
        "\n",
        "trainer.save_model(\"/content/drive/MyDrive/EsBERTa\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFu4jCDI2ig3"
      },
      "source": [
        "Don't forget to share your model!\n",
        "\n",
        "[How to upload a model to the ðŸ¤— Model Hub.](https://huggingface.co/transformers/model_sharing.html)"
      ]
    }
  ]
}